/*
The MIT License (MIT)

Copyright (c) 2014 Chris Wilson

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/

//set up the WebKit. 
var audioContext = new AudioContext();
var isPlaying = false;
var sourceNode = null;
var analyser = null;
var theBuffer = null;
var detectorElem, 
	canvasContext,
	pitchElem,
	noteElem,
	detuneElem,
	detuneAmount;
var WIDTH=300;
var CENTER=150;
var HEIGHT=42;
var confidence = 0;
var currentPitch = 0;

window.onload = function() {
    //request a file to upload
	var request = new XMLHttpRequest();
	//the file path to load in the sound. True is simply to say load 
	//asynchronously and let us know when it is loaded. 
	request.open("GET", "sounds/PianoC_StartMusic.wav", true);
	//get the raw binary data from the wav file. 
	request.responseType = "arraybuffer";
	//need on load function. 
	request.onload = function() {
	//pass the file from load operation into a buffer. 
	  audioContext.decodeAudioData( request.response, function(buffer) { 
	    	theBuffer = buffer;
		} );
	}
	//finally load the file.. 
	request.send();

    
	detectorElem = document.getElementById( "detector" );
	pitchElem = document.getElementById( "pitch" );
	noteElem = document.getElementById( "note" );
	detuneElem = document.getElementById( "detune" );
	detuneAmount = document.getElementById( "detune_amt" );
	canvasContext = document.getElementById( "output" ).getContext("2d");

	detectorElem.ondragenter = function () { 
		this.classList.add("droptarget"); 
		return false; };
	detectorElem.ondragleave = function () { this.classList.remove("droptarget"); return false; };
	detectorElem.ondrop = function (e) {
  		this.classList.remove("droptarget");
  		e.preventDefault();
		theBuffer = null;

	  	var reader = new FileReader();
	  	reader.onload = function (event) {
	  		audioContext.decodeAudioData( event.target.result, function(buffer) {
	    		theBuffer = buffer;
	  		}, function(){alert("error loading!");} ); 

	  	};
	  	reader.onerror = function (event) {
	  		alert("Error: " + reader.error );
		};
	  	reader.readAsArrayBuffer(e.dataTransfer.files[0]);
	  	return false;
	};



}
//make sure an alert is sent if the Audio API fails
function error() {
    alert('Stream generation failed.');
}

function getUserMedia(dictionary, callback) {
    try {
        navigator.getUserMedia = 
        	navigator.getUserMedia ||
        	navigator.webkitGetUserMedia ||
        	navigator.mozGetUserMedia;
        navigator.getUserMedia(dictionary, callback, error);
    } catch (e) {
        alert('getUserMedia threw exception :' + e);
    }
}

//this is from WebAudio. It requests the audio input stream. 
//then a node can be connected to anything... 
function gotStream(stream) {
    // Create an AudioNode from the stream.
    var mediaStreamSource = audioContext.createMediaStreamSource(stream);

    // Connect it to the destination.
    analyser = audioContext.createAnalyser();
    //set the FFT window size to 2048
    analyser.fftSize = 2048;
    //assign the window size to the input stream to divide into appropriate sized blocks.
    mediaStreamSource.connect( analyser );
    //call the updated pitch that has had auto correlation applied. 
    updatePitch();
}

function toggleLiveInput() {
    getUserMedia({audio:true}, gotStream);
}

function togglePlayback() {
    var now = audioContext.currentTime;

    if (isPlaying) {
        //stop playing and return
        sourceNode.stop( now );
        sourceNode = null;
        analyser = null;
        isPlaying = false;
		if (!window.cancelAnimationFrame)
			window.cancelAnimationFrame = window.webkitCancelAnimationFrame;
        window.cancelAnimationFrame( rafID );
        return "start";
    }

    sourceNode = audioContext.createBufferSource();
    sourceNode.buffer = theBuffer;
    sourceNode.loop = true;

    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    sourceNode.connect( analyser );
    analyser.connect( audioContext.destination );
    sourceNode.start( now );
    isPlaying = true;
    isLiveInput = false;
    updatePitch();

    return "stop";
}

var rafID = null;
var tracks = null;
var buflen = 2048;
var buf = new Uint8Array( buflen );
var MINVAL = 134;  // 128 == zero.  MINVAL is the "minimum detected signal" level.

/*
function findNextPositiveZeroCrossing( start ) {
	var i = Math.ceil( start );
	var last_zero = -1;
	// advance until we're zero or negative
	while (i<buflen && (buf[i] > 128 ) )
		i++;
	if (i>=buflen)
		return -1;

	// advance until we're above MINVAL, keeping track of last zero.
	while (i<buflen && ((t=buf[i]) < MINVAL )) {
		if (t >= 128) {
			if (last_zero == -1)
				last_zero = i;
		} else
			last_zero = -1;
		i++;
	}

	// we may have jumped over MINVAL in one sample.
	if (last_zero == -1)
		last_zero = i;

	if (i==buflen)	// We didn't find any more positive zero crossings
		return -1;

	// The first sample might be a zero.  If so, return it.
	if (last_zero == 0)
		return 0;

	// Otherwise, the zero might be between two values, so we need to scale it.

	var t = ( 128 - buf[last_zero-1] ) / (buf[last_zero] - buf[last_zero-1]);
	return last_zero+t;
}
//*/

var noteStrings = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];

function noteFromPitch( frequency ) {
	var noteNum = 12 * (Math.log( frequency / 440 )/Math.log(2) );
        //not sure what this is doing? printing out the return value gives numbers that go from 5000 to - numbers
        //console.log("PitchMidiNote = " + Math.round( noteNum ) + 69);
	return Math.round( noteNum ) + 69;
        
}

function frequencyFromNoteNumber( note ) {
        //print out the frequency to console
        //console.log("Pitch Midi Note = " + 440 * Math.pow(2,(note-69)/12));
	return 440 * Math.pow(2,(note-69)/12);//this formula gives the midi notes version value of frequency 
}

function centsOffFromPitch( frequency, note ) {
	return ( 1200 * Math.log( frequency / frequencyFromNoteNumber( note ))/Math.log(2) );
}

// this is a float version of the algorithm below - but it's not currently used.
/*
function autoCorrelateFloat( buf, sampleRate ) {
	var MIN_SAMPLES = 4;	// corresponds to an 11kHz signal
	var MAX_SAMPLES = 1000; // corresponds to a 44Hz signal
	var SIZE = 1000;
	var best_offset = -1;
	var best_correlation = 0;
	var rms = 0;

	if (buf.length < (SIZE + MAX_SAMPLES - MIN_SAMPLES))
		return -1;  // Not enough data

	for (var i=0;i<SIZE;i++)
		rms += buf[i]*buf[i];
	rms = Math.sqrt(rms/SIZE);

	for (var offset = MIN_SAMPLES; offset <= MAX_SAMPLES; offset++) {
		var correlation = 0;

		for (var i=0; i<SIZE; i++) {
			correlation += Math.abs(buf[i]-buf[i+offset]);
		}
		correlation = 1 - (correlation/SIZE);
		if (correlation > best_correlation) {
			best_correlation = correlation;
			best_offset = offset;
		}
	}
	if ((rms>0.1)&&(best_correlation > 0.1)) {
		console.log("f = " + sampleRate/best_offset + "Hz (rms: " + rms + " confidence: " + best_correlation + ")");
	}
//	var best_frequency = sampleRate/best_offset;
}
*/


//this is the algorithm to understand!
//it takes the buffer size of 2048 and  a sample rate of 44100. 
function autoCorrelate( buf, sampleRate ) {

        // my code to smooth out algorithm
       //At the moment it looks like Frequency may be better to take than MIDI? 
       //create an array to store all MIDI pitches coming in from the 
       //fill the array with a list for now to trial it first so I know the numbers
       //as the pitch in will be very hard to work with initially
       var pitchIn = new Array("50", "51", "52", "52", "50", "50", "50", "53", "58", "60", "61", "60", "60", "60", "60");//var pitchIn = new Array("");
       var counter = 0; // to keep track of the number of samples coming in
       var sum = 0;//variabel to store the sum of initial array
       var startingTotal = 0;//give the total length of initial array

       //this is the standard auto corrilation algorithm
	var MIN_SAMPLES = 4;	// corresponds to an 11kHz signal
	var MAX_SAMPLES = 1000; // corresponds to a 44Hz signal
	var SIZE = 1000;//this correlates to the window size?
	//var SIZE = 2000; 
	var best_offset = -1;//a variable to offset the phases for comparing intensities. 
	var best_correlation = 0;
	var rms = 0;

	confidence = 0;
	currentPitch = 0;

	if (buf.length < (SIZE + MAX_SAMPLES - MIN_SAMPLES))
		return;  // Not enough data
    
        //iterate 1000 times over the initial signal
	for (var i=0;i<SIZE;i++) {
		var val = (buf[i] - 128)/128;//normalising power spectrum. 
		rms += val*val;
	}
	
	//square the result values. 
	rms = Math.sqrt(rms/SIZE);//average rms for buffer

    
	for (var offset = MIN_SAMPLES; offset <= MAX_SAMPLES; offset++) {
		var correlation = 0;//local variable to store the offset correlations
               
        //iterate through and offset up to window size(SIZE).. Same as MAX_SAMPLES
		for (var i=0; i<SIZE; i++) {
			correlation += Math.abs(((buf[i] - 128)/128)-((buf[i+offset] - 128)/128));//calculating value between 0 and 1 using absolute value to normailse signal. 
                       
		}
		correlation = 1 - (correlation/SIZE);//
		if (correlation > best_correlation) {
			best_correlation = correlation;
			best_offset = offset;
		}
	}
	
	//adjust threshold? Get it less twitchy. Lengthen the sample length? Stop fluctuation? 
	//if ((rms>0.1)&&(best_correlation > 0.1)) {
	if ((rms>0.01)&&(best_correlation > 0.01)) {
		confidence = best_correlation * rms * 10000;
		currentPitch = sampleRate/best_offset;
		// console.log("f = " + sampleRate/best_offset + "Hz (rms: " + rms + " confidence: " + best_correlation + ")")
                 console.log("frequecy = " +  currentPitch + "Hz");//gives the frequncy
        }

//loop through all the pitches that come in for the melody
for (var i = 0; i < pitchIn.length; i ++)
{  
   //add all the notes together to create one long number
   //have to parse the input to int or float before they can be edited properly as numbers.  
   pitchIn[i] = parseFloat(pitchIn[i], 10);
   sum += pitchIn[i];//get the total of all current notes
   //use the counter i to access any date needed
   //update the array numbers in the console to see whats there.
   console.log("Array value = " + pitchIn[i]);
   counter ++; 
   
}



startingTotal =  parseFloat(pitchIn.length);
console.log("Starting Total = " + startingTotal);

//need to create a moving average filter. 
//here is a link to a pseudo code version. 
//http://rosettacode.org/wiki/Averages/Simple_moving_average
//http://stackoverflow.com/questions/3760506/smoothing-values-over-time-moving-average-or-something-better

/*
//build an averager method once a section of the sample is chosen
*/

//function movingAverageFilter( pitches){}
var indexChange;//variable to define the index boundaries if the moving average jumps more than a certain amount. 
var confidenceOfBoundaryChange;//variable to track the confidence of a possible change. 
var smallestBoundary = 1;//using midinotes or Frequency will alter this..  
var largestBoundary = 2;//using midinotes or Frequency will alter this.. 




var lastIndex = parseFloat(pitchIn[pitchIn.length -1]);//get last index to be added make sure it is parsed to be usable 
console.log("LastIndex = " + lastIndex);
console.log("Sum = " + sum);
console.log("N = " + pitchIn.length);

//runningAverage needs to = (sum + new_number) / (total + 1) 
var runningAverage = (sum + lastIndex) / (startingTotal +  counter);//1 needs to iterate up once for each new note reading. 
console.log("RunningAverage Note value = " + runningAverage);

//two methods 1 Add a new number in to the array and take the average of the running total. 
// or 2 multiple the average of the first few fewquencies and divide by 


/*
//calculate the average note value of each region 
*/
var sumOfNotes = 0;

for(var noteValue = 0; noteValue < pitchIn.length; noteValue ++)
{
    //add all the notes together to create one long number
    //have to parse the input to int or float before they can be edited properly as numbers.  
    pitchIn[noteValue] = parseFloat(pitchIn[noteValue], 10);
    sumOfNotes =  sumOfNotes + pitchIn[noteValue];
}

//outside the for loop find out the average of the note region
var averageOfNoteRegion = sumOfNotes / pitchIn.length; 
console.log("Sum of Notes = " + sumOfNotes);
console.log("Average Note value = " + averageOfNoteRegion);























                  


//	}
//	var best_frequency = sampleRate/best_offset;
}

//get all pitches into a buffer. 
//then vibrato filter. 
//try a low pass filter to the input. 
//apply an averaging filter. 
//an average over the length of a quaver. 
//short term averaging
//if current average jumps move onto next note. 


function updatePitch( time ) {
	var cycles = new Array;
	analyser.getByteTimeDomainData( buf );


/*
// old zero-crossing code

	var i=0;
	// find the first point
	var last_zero = findNextPositiveZeroCrossing( 0 );

	var n=0;
	// keep finding points, adding cycle lengths to array
	while ( last_zero != -1) {
		var next_zero = findNextPositiveZeroCrossing( last_zero + 1 );
		if (next_zero > -1)
			cycles.push( next_zero - last_zero );
		last_zero = next_zero;

		n++;
		if (n>1000)
			break;
	}

	// 1?: average the array
	var num_cycles = cycles.length;
	var sum = 0;
	var pitch = 0;

	for (var i=0; i<num_cycles; i++) {
		sum += cycles[i];
	}

	if (num_cycles) {
		sum /= num_cycles;
		pitch = audioContext.sampleRate/sum;
	}

// confidence = num_cycles / num_possible_cycles = num_cycles / (audioContext.sampleRate/)
	var confidence = (num_cycles ? ((num_cycles/(pitch * buflen / audioContext.sampleRate)) * 100) : 0);


/*
	console.log( 
		"Cycles: " + num_cycles + 
		" - average length: " + sum + 
		" - pitch: " + pitch + "Hz " +
		" - note: " + noteFromPitch( pitch ) +
		" - confidence: " + confidence + "% "
		);
*/
	// possible other approach to confidence: sort the array, take the median; go through the array and compute the average deviation
	autoCorrelate( buf, audioContext.sampleRate );

// 	detectorElem.className = (confidence>50)?"confident":"vague";

	canvasContext.clearRect(0,0,WIDTH,HEIGHT);

 	if (confidence <10) {
 		detectorElem.className = "vague";
	 	pitchElem.innerText = "--";
		noteElem.innerText = "-";
		detuneElem.className = "";
		detuneAmount.innerText = "--";
 	} else {
	 	detectorElem.className = "confident";
	 	pitchElem.innerText = Math.floor( currentPitch ) ;
	 	var note =  noteFromPitch( currentPitch );
		noteElem.innerHTML = noteStrings[note%12];
		var detune = centsOffFromPitch( currentPitch, note );
		if (detune == 0 ) {
			detuneElem.className = "";
			detuneAmount.innerHTML = "--";

			// TODO: draw a line.
		} else {
			if (Math.abs(detune)<10)
				canvasContext.fillStyle = "green";
			else
				canvasContext.fillStyle = "red";

			if (detune < 0) {
	  			detuneElem.className = "flat";
			}
			else {
				detuneElem.className = "sharp";
			}
  			canvasContext.fillRect(CENTER, 0, (detune*3), HEIGHT);
			detuneAmount.innerHTML = Math.abs( Math.floor( detune ) );
		}
	}

	if (!window.requestAnimationFrame)
		window.requestAnimationFrame = window.webkitRequestAnimationFrame;
	rafID = window.requestAnimationFrame( updatePitch );
       
}
